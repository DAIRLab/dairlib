admm_iter: 4
rho: 0.1
rho_scale: 2.5
num_threads: 6
num_outer_threads: 4
# delta_option: 1
# options are 'MIQP' or 'QP'
projection_type: 'MIQP'
# options are 'stewart_and_trinkle' or 'anitescu'
contact_model: 'anitescu'
# These mu values are the effective friction coefficients for the represented 
# contact pair. These values match how drake computes frictional coefficients.
# mu_effective = 2*mu1*mu2 / (mu1 + mu2). See urdfs for mu1 and mu2.
# The contact pairs are ordered as ee_jack, capsule1_ground, capsule2_ground,
# and capsule3_ground.
mu: [[1, 1],
    [1, 1, 1]]
dt: 0.05    # This is used by the radio input currently but we don't use it.
planning_dt: 0.1
execution_dt: 0.03
num_friction_directions: 2
# If num_contacts_index is 0, then we use 4 closest contacts with resolved 
# ee-jack contact.
# If num_contacts_index is 1, then we use 6 contacts without resolving 
# ee-jack contact.
# If num_contacts_index is 2, then we use 4 closest ee-jack contacts with an 
# additional contact between ee and ground.
# If num_contacts_index is 3, then we use 6 ee-jack contacts with an additional
#  contact between ee and ground.
num_contacts_index: 0
# num_contacts changes based on the num_contacts_index.
num_contacts: [2,3]
N: 5
# This param has to do with the xbox input?
use_predicted_x0: false
solve_time_filter_alpha: 0.95
# Workspace Limits
world_x_limits: [-2, 2]
world_y_limits: [-2, 2]
world_z_limits: [-2, 2]
workspace_margins: 0.05
u_horizontal_limits: [-50, 50]
u_vertical_limits: [0, 50]
gamma: 1.0  # discount factor on MPC costs
# Penalty on matching projected variables
g_x: [0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005]
g_gamma: [[0.0005, 0.0000001],
          [0.0005, 0.0000001, 0.0000001]]
g_lambda_n: [[0.0005, 0.0000001],
             [0.0005, 0.0000001, 0.0000001]]
g_lambda_t: [[0.0005, 0.0005, 0.0005, 0.0005, 0.0000001, 0.0000001, 0.0000001, 0.0000001],
             [0.0005, 0.0005, 0.0005, 0.0005, 0.0000001, 0.0000001, 0.0000001, 0.0000001, 0.0000001, 0.0000001, 0.0000001, 0.0000001]]
g_lambda: [[0.0005, 0.0005, 0.0005, 0.0005, 0.000000, 0.000000, 0.000000, 0.000000],
           [0.0005, 0.0005, 0.0005, 0.0005, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]]
g_u: [0.0005, 0.0005, 0.0005]

# Penalty on matching the QP variables
u_x: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
u_gamma: [[1, 1],
          [1, 1, 1]]
u_lambda_n: [[1, 1],
             [1, 1, 1]]
u_lambda_t: [[1, 1, 1, 1, 1, 1, 1, 1],
             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
u_lambda: [[1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
u_u: [1, 1, 1]


warm_start: false     # TODO: Check if we use this. Delete otherwise.

# matrix scaling
w_Q: 1
w_R: 1
# Penalty on all decision variables, assuming scalar
w_G: 100000
# Penalty on all decision variables, assuming scalar
w_U: 1

# alpha value for qp projection. As alpha -> 0, any error in complimentarity 
# constraints also approaches 0. 
qp_projection_alpha: 0.0001
qp_projection_scaling: 1000

# n_lambda = 2 * n_contacts + 2 * n_contacts * num_friction_directions
# size = n_x ( 7 + 3 + 6 + 3 ) + n_lambda (2 * 3  + 2 * 3 * 2) + n_u (3) = 40 for stewart and trinkle
# size = n_x ( 7 + 3 + 6 + 3 ) + n_lambda (2 * 3 * 2) + n_u (3) = 34 for anitescu
# g_size: 49
# u_size: 49
#g_size: 34
#u_size: 34

# State Tracking Error, assuming diagonal
# state ordering: [xee, yee, zee, qbw, qbx, qby, qbz, xb, yb, zb, 
#                  veex, veey, veez, wbx, wby, wbz, vbx, vby, vbz]
q_vector: [500, 500, 500,        # end effector position
           0, 0, 0, 0,              # object orientation
           800000, 800000, 20000,    # object position
           10, 10, 10,              # end effector linear velocity
           0, 0, 0,                 # object angular velocity
           0.1, 0.1, 0.1]           # object linear velocity
# q_vector: [150, 150, 150, 0, 1, 1, 0, 1000000, 1000000, 100000000,
#            5, 5, 15, 10, 10, 1, 5, 5, 5]
# q_vector: [100, 100, 500, 0, 0, 0, 0, 1000000, 1000000, 100000000,
#            5, 5, 15, 10, 10, 1, 5, 5, 5]

# Penalty on all decision variables
# g_vector: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
#g_vector: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
# Penalty on all decision variables
# u_vector: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1,
          #  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
#u_vector: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1,
#           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

# Penalty on end effector (x,y,z) force efforts, assuming diagonal
r_vector: [0.01, 0.01, 0.01]

