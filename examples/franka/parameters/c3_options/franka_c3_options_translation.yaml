admm_iter: 2
rho: 0.0
rho_scale: 4
num_threads: 5
delta_option: 1
# options are 'MIQP' or 'QP'
projection_type: 'MIQP'
# options are 'stewart_and_trinkle' or 'anitescu'
#contact_model: 'anitescu'
contact_model: 'stewart_and_trinkle'
warm_start: false
use_predicted_x0: false
use_robust_formulation: false
end_on_qp_step: false
solve_time_filter_alpha: 0.95
#publish_frequency : 0
publish_frequency: 0

# Workspace Limits
workspace_limits: [[1.0, 0.0, 0.0, 0.4, 0.6],
                   [0.0, 1.0, 0.0, -0.2, 0.2],
                   [0.0, 0.0, 1.0, 0.3, 0.6]]
workspace_margins: 0.05

u_horizontal_limits: [-50, 50]
u_vertical_limits: [-50, 50]

mu: [0.6, 0.6, 0.6]
dt: 0.05
solve_dt: 0.05
num_friction_directions: 2
num_contacts: 3
N: 5
gamma: 1

# matrix scaling
w_Q: 50
w_R: 25
# Penalty on all decision variables, assuming scalar
w_G: 0.1
# Penalty on all decision variables, assuming scalar
w_U: 0.5

# State Tracking Error, assuming diagonal
q_vector: [175, 175, 175, 1, 1, 1, 1, 15000, 15000, 15000,
           5, 5, 5, 10, 10, 10, 5, 5, 5]

# Penalty on efforts, assuming diagonal
r_vector: [0.15, 0.15, 0.1]

# Penalty on all decision variables
g_x: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
g_gamma: [50, 50, 50]
g_lambda_n: [50, 50, 50]
g_lambda_t: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
g_lambda: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]
g_u: [1, 1, 1]

# Penalty on all decision variables
u_x: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
u_gamma: [100, 100, 100]
u_lambda_n: [100, 100, 100]
u_lambda_t: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]
u_lambda: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
u_u: [30, 30, 30]
