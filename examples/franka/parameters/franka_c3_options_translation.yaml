admm_iter: 4
rho: 0.0
rho_scale: 2
num_threads: 5
delta_option: 1
# options are 'MIQP' or 'QP'
projection_type: 'MIQP'
# options are 'stewart_and_trinkle' or 'anitescu'
#contact_model: 'anitescu'
contact_model: 'stewart_and_trinkle'
warm_start: true
use_predicted_x0: false
solve_time_filter_alpha: 0.9

# Workspace Limits
world_x_limits: [0.4, 0.6]
world_y_limits: [-0.2, 0.2]
world_z_limits: [0.3, 0.6]
workspace_margins: 0.05

u_horizontal_limits: [-10, 10]
u_vertical_limits: [0, 30]

mu: [0.6, 0.6, 0.6]
dt: 0.05
solve_dt: 0.05
num_friction_directions: 2
num_contacts: 3
N: 5
gamma: 1

# matrix scaling
w_Q: 50
w_R: 1
# Penalty on all decision variables, assuming scalar
w_G: 1
# Penalty on all decision variables, assuming scalar
w_U: 0.5

# State Tracking Error, assuming diagonal
q_vector: [175, 175, 175, 10, 10, 10, 10, 5000, 5000, 5000,
           5, 5, 10, 1, 1, 1, 5, 5, 5]

# Penalty on efforts, assuming diagonal
r_vector: [0.1, 0.1, 0.1]

# Penalty on all decision variables
g_x: [1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
g_gamma: [1, 1, 1]
g_lambda_n: [1, 1, 1]
g_lambda_t: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
g_lambda: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]
g_u: [1, 1, 1]

# Penalty on all decision variables
u_x: [1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 1, 1, 1, 10, 10, 10, 10, 10, 10]
u_gamma: [1, 1, 1]
u_lambda_n: [1, 1, 1]
u_lambda_t: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
u_lambda: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
u_u: [10, 10, 10]
