admm_iter: 3
rho: 0  #This isn't used anywhere!
rho_scale: 3  #2.3
num_threads: 5
num_outer_threads: 4
# delta_option: 1
# options are 'MIQP' or 'QP'
projection_type: 'MIQP'
# options are 'stewart_and_trinkle' or 'anitescu'
contact_model: 'anitescu'
# These mu values are the effective friction coefficients for the represented 
# contact pair. These values match how drake computes frictional coefficients.
# mu_effective = 2*mu1*mu2 / (mu1 + mu2). See urdfs for mu1 and mu2.
# The contact pairs are ordered as ee_jack, capsule1_ground, capsule2_ground,
# and capsule3_ground.
mu: [[0.4615, 0.4615, 0.4615, 0.4615],
    [0.4615, 0.4615, 0.4615, 0.4615, 0.4615, 0.4615],
    [0.4615, 1, 0.4615, 0.4615, 0.4615],
    [0.4615, 0.4615, 0.4615, 1, 0.4615, 0.4615, 0.4615],
    [0.4615, 0.4615, 0.4615, 0.4615, 0.4615]]
dt: 100    # This is not used for the sampling_based controller that uses 
           # planning and execution dt instead. This param is being left in 
           #  for compatibility with other c3 controllers.
planning_dt: 0.05
execution_dt: 0.1   # unused
num_friction_directions: 2
# If num_contacts_index is 0, then we use 1 ee-jack contact and 3 ground-jack
# contacts.
# If num_contacts_index is 1, then we use 6 contacts without resolving 
# ee-jack contact.
# If num_contacts_index is 2, then we use 4 closest ee-jack contacts with an 
# additional contact between ee and ground.
# If num_contacts_index is 3, then we use 6 ee-jack contacts with an additional
#  contact between ee and ground.
# If num_contacts_index is 4, then we use 1 ee-jack contact and 4 ground-jack
# contacts.
num_contacts_index: 4
# num_contacts changes based on the num_contacts_index.
num_contacts: [4,6,5,7,5]
# If two numbers, the first is for ee-jack contact(s) and the second is for
# ground-jack contact(s).  If three, the middle is for the ee-ground contact.
resolve_contacts_to_list: [[1,3],
                           [3,3],
                           [1,1,3],
                           [3,1,3],
                           [1,4]]
N: 5
use_predicted_x0: false   # unused for sampling-based c3 controller
use_predicted_x0_c3: true
use_predicted_x0_repos: true
at_least_predict_first_planned_trajectory_knot: true

solve_time_filter_alpha: 0.95
# Workspace Limits
world_x_limits: [0.25, 0.65]
world_y_limits: [-0.45, 0.45]
world_z_limits: [0.05, 0.2]
workspace_margins: 0.05
u_horizontal_limits: [-50, 50]
u_vertical_limits: [-50, 50]

# minimum end effector z-state constraint in c3
ee_z_state_min: 0.02

gamma: 1.0  # discount factor on MPC costs
# Penalty on matching projected variables
g_x: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
g_gamma: [[1, 1, 1, 1],
          [1, 1, 1, 1, 1, 1]]
g_lambda_n: [[1, 1, 1, 1],
             [1, 1, 1, 1, 1, 1]]
g_lambda_t: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
g_lambda: [[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],
           [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],
           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
           [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]]
g_u: [30, 30, 30]

# Penalty on matching the QP variables
u_x: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1]
u_gamma: [[1, 1, 1, 1],
          [1, 1, 1, 1, 1, 1]]
u_lambda_n: [[1, 1, 1, 1],
             [1, 1, 1, 1, 1, 1]]
u_lambda_t: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
# u_lambda is not used for the QP projection. It gets overwritten by alpha*F.
u_lambda: [[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],
            [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]]
u_u: [0.01, 0.01, 0.01]


warm_start: false     # TODO: Check if we use this. Delete otherwise.

# matrix scaling
w_Q: 45
w_R: 1
# Penalty on all decision variables, assuming scalar
w_G: 0.25
# Penalty on all decision variables, assuming scalar
w_U: 0.25

# alpha value for qp projection. As alpha -> 0, any error in complimentarity 
# constraints also approaches 0. 
qp_projection_alpha: 0.01
qp_projection_scaling: 1

# n_lambda = 2 * n_contacts + 2 * n_contacts * num_friction_directions
# size = n_x ( 7 + 3 + 6 + 3 ) + n_lambda (2 * 3  + 2 * 3 * 2) + n_u (3) = 40 for stewart and trinkle
# size = n_x ( 7 + 3 + 6 + 3 ) + n_lambda (2 * 3 * 2) + n_u (3) = 34 for anitescu
# g_size: 49
# u_size: 49
#g_size: 34
#u_size: 34

# State Tracking Error, assuming diagonal
# state ordering: [xee, yee, zee, qbw, qbx, qby, qbz, xb, yb, zb, 
#                  veex, veey, veez, wbx, wby, wbz, vbx, vby, vbz]
# ORIENTATION GOAL GAINS
# q_vector_position_and_orientation: [0, 0, 0,        # end effector position
#            3000, 3000, 3000, 3000,              # object orientation
#            200, 200, 200,    # object position
#            0.1, 0.1, 0.1,              # end effector linear velocity
#            2.5, 2.5, 2.5,                 # object angular velocity
#            1, 1, 1]           # object linear velocity
q_vector_position_and_orientation: [0, 0, 0,        # end effector position
           100, 100, 100, 100,              # object orientation
           0, 0, 1,    # object position
           0.05, 0.05, 0.05,              # end effector linear velocity
           100, 100, 100,                 # object angular velocity
           0, 0, 0]           # object linear velocity

# POSITION GOAL GAINS
q_vector: [0, 0, 0,        # end effector position
           0, 0, 0, 0,              # object orientation
           1500, 1500, 1500,    # object position
           0.1, 0.1, 0.1,              # end effector linear velocity
           0.01, 0.01, 0.01,                 # object angular velocity
           1, 1, 1]           # object linear velocity

# Penalty on all decision variables
# g_vector: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
#g_vector: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
# Penalty on all decision variables
# u_vector: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1,
          #  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
#u_vector: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1,
#           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

# Penalty on end effector (x,y,z) force efforts, assuming diagonal
r_vector: [0.01, 0.01, 0.01]
